\chapter{Processing libraries}

This milestone summarizes the development results of stages \ref{num:stage2} - \ref{num:stage8} described in \Nameref{sec:developmentStages}.

\section{Reflection-based member provider}

\subsection{Reflection library}

This is the most important library of this project, as it shall provide type and member information, which will then be mapped to extracted documentation. If fully implementing this library using reflection fails, then the complexity of the project would skyrocket, as the only other viable option is parsing source code directly.

The proof of concept (see \ref{chap:proofConcept}) was built using \ref{gloss:dotnetlabel} Framework and utilized the built-in reflection capabilities. Moreover, all tests were done on non-complex assemblies without references. This was a fatal oversight. \ref{gloss:dotnetlabel} Core provides reflection capabilities; however, it does not allow loading an assembly without its references. This meant, that the researched solution was of no use, and an alternative had to be found.

Fortunately, after considerable effort, it was. The issue was solved by a third-party reflection library called \textit{dnlib} which is most notably used for obfuscating code in \ref{gloss:dotnetlabel} assemblies using its assembly modification features. For the purposes of reading and extracting required data, \textit{dnlib} was more than sufficient.

\subsection{Separation of types}

The documentation-generating tool would allow the selecting of individual assemblies. This implies, that a user can select only a subset of assemblies generated by a project; thus, introducing the possibility of exclusion of a referenced assembly and its types.

Given that, the member resolver would produce a set of types defined within the given assembly, and types referenced by their members. Once all assemblies are loaded, and the next process accesses a referenced type, it can verify whether or not the type is provided via the loaded assemblies. If it is not, only the type name is preserved.

This is especially important for the Linker component, which will create links between references and documentation of said types.

\subsection{Dynamic types and value types}

Both \textit{dnlib} and the built-in \ref{gloss:dotnetlabel} reflection do not provide complete details about the extracted types and members. This implies that additional effort has to be made to extract the necessary information. In some cases, such an attempt is much more considerable than in others.

The most complex cases were for members that either returned, or accepted \lstinline[language=csh]{dynamic} types, and value tuples. A \lstinline[language=csh]{dynamic} type is a regular \lstinline[language=csh]{object} type, but with compile-time syntax checking disabled. This allows developers to access type members without casting it to their corresponding type. A value tuple is an extension of the regular C\# tuple, but with more syntactic sugar that allows labeling each tuple entry with a name.

\begin{lstlisting}[language=csh]
    Tuple<int, string> studentAgeClassic; // Classic tuple

    (int age, string name) studentAgeNew; // Value tuple with labels
    (int, string) studentAgeNewNameless; // Value tuple without labels
\end{lstlisting}

Reflection displays \lstinline[language=csh]{dynamic} types as \lstinline[language=csh]{object} and hides value tuple labels. This obfuscates the edge cases mentioned above.

Necessary information for deobfuscating said cases is hidden in attributes decorating the given member. Said attributes provide a flat map indicating which types are \lstinline[language=csh]{dynamic} and value tuple labels. However, this result cannot be used straight away, since returned, or accepted types by a member can be more complex. For example, the type can be a tuple of objects, some of which are dynamic. Or the type could be a value tuple with one of its entries also being a value tuple. This introduces structural complexity, that cannot be mapped trivially to a flat list provided by the attributes.

The solution for this is a complex algorithm for processing the flat list from the attributes, filtering out unnecessary information, and mapping it to the provided type from the member.

\subsection{Missing features}

The developed implementation of the member resolver component covers many cases and provides a lot of useful information about types from given assemblies. Unfortunately, not everything had been implemented, either because it was not a priority, or was unclear on how to implement it.

\subsubsection{Attributes}

Attributes are annotations for types, members, or parameters, that add metadata. The tool can generate documentation for attributes, as they are just classes inheriting a special \lstinline[language=csh]{Attribute} class, but it does not link attributes to types, members, or parameters they decorate.

\subsubsection{Links to source code}

It can be beneficial to quickly access a line of code defining a given documented type or member. For example, the documentation is hosted on a Git platform, and it links to the exact lines of the source code. Nevertheless, it was not possible to create a working solution, as for unknown reasons some assemblies provided necessary information, while others did not. Thus, this feature cannot be delivered, as it is unstable.

\subsubsection{Reference to source assembly}

It can be beneficial to see from which assembly the given types were extracted. It is trivial to implement; although, this feature had a low priority and was left out of this development cycle.

\subsubsection{Multicast delegates}

Regular C\# delegates are defined within a class; whereas, multicast delegates are defined on the same level as a class.
The existence of multicast delegates was, unfortunately, overlooked when developing the tool.
Such delegates are compiled as classes that are deriving from the \lstinline[language=csh]{MulticastDelegate} base class.
This means that they are captured, but are incorrectly represented as classes.

\section{XML documentation provider}

Writing the \ref{itm:xml} documentation processing component involved analyzing Microsofts documentation of supported tags, defining the corresponding data structures to hold the extracted documentation, and attempting to more complex issues like locating inherited documentation.

\subsection{Tags documentation}

Microsofts documentation for some tags, such as the list tag (see \ref{sec:listTag}), is vague. There are missing examples and details that would fully define how to use said tags. Moreover, Microsoft's IDE, Visual Studio, does not display some of the tags (including the list tag). Thus, defining logic for handling such tags was unnecessarily slowed down by research outside of Microsft's documentation.

\subsection{Dependency on the member provider}

Because of the documentation inheritance tag (see \ref{sec:inheritdocTag}), the documentation provider must be capable of locating the source of inheritance. This information is not necessarily present in the source \ref{itm:xml}, as specifying the inheritance source is optional and only needed if more than one source provides unique documentation for a single inherited member.

Thus, the documentation resolver had to have access to retrieved data from the member provider. Inherited documentation would be lazily loaded once needed. That is to make the documentation provider and member provider work in parallel instead of waiting for one another. This lazy-loading technique is utilized throughout the tool to improve the parallelization of processes dependent on each other.

\section{Linker} \label{sec:linker}

The linker component was one of the projects chosen to be developed using F\#. It was chosen because the linker does not need any data structures and simply generates a output, based on the processed input.

\subsection{Git specific logic}

This component is focused on providing link and anchor formats for a select number of Git hosting platforms. If not for issues with Bitbucket and Azure DevOps, it would support a total of four platforms. Instead, only GitHub and GitLab are supported.

\section{Markdown elements}

The markdown elements provider component was researched in the proof of concept stage (see \ref{chap:proofConcept}), and the gained knowledge had proven sufficient for implementing this component.

\section{MermaidJS diagram generator}

TODO

\section{Composer}

The composer component is one of the most complicated, as it takes care of mapping the extracted data to each other, and filling it into the provided elements. This component was also chosen to be developed in F\#, for the same reasons as the linker (see \ref{sec:linker}). Whether or not that was a mistake, is still up to debate; nevertheless, the resulting code is complex is difficult to maintain.

\subsection{Composed structure}

The composer is responsible for creating the documentation structure. The defined structure was inpired by the one generated by Doxygen (see \ref{sec:doxygen}):
\begin{itemize}
    \item Inheritance diagram
    \item Table of contents for Methods and Properties
    \item Full documentation
\end{itemize}

\subsubsection{Inheritance diagram}

The inheritance diagram content is provided by a diagram generating component. The purpose is to see what interfaces and base classes are inherited by the given documented type. Additionally, the diagram would display what generic parameters each type in the inheritance tree has, alongside their constraints.

\subsubsection{Table of contents}

The table of contents serves as a brief overview of the types method and property members.

\subsubsection{Full documentation}

TODO

\section{Printer}

The printer component was the simplest to implement, as it only processes the composer generated output, and writes it into \ref{gloss:markdown} files.